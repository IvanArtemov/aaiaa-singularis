# Singularis Challenge - AAIAA Project

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Configure Environment

Copy `.env.example` to `.env` and add your API keys:

```bash
cp .env.example .env
```

Edit `.env`:
```bash
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxx
```

### 3. Configure LLM Provider

Edit `src/config/llm_config.yaml` to choose your provider:

```yaml
# Switch between "openai" or "ollama"
active_provider: "openai"
```

### 4. Run Examples

```bash
# LLM adapters example
python scripts/example_adapters.py

# Paper fetcher example
python scripts/example_fetchers.py

# Telegram Bot (requires TELEGRAM_BOT_TOKEN in .env)
python scripts/run_telegram_bot.py
```

### 5. Run Tests

```bash
# Run all tests
pytest

# Run only integration tests
pytest tests/integration/ -v

# Run with coverage report
pytest --cov=src --cov-report=html
```

---

## ğŸ”Œ LLM Adapters

### Switching Providers

**Option 1: In config file**
```yaml
# src/config/llm_config.yaml
active_provider: "ollama"  # Change here
```

**Option 2: In code**

```python
from src.llm_adapters import get_llm_adapter

# Use specific provider
llm = get_llm_adapter("openai")
# or
llm = get_llm_adapter("ollama")
```

### Usage Examples

**Text Generation:**

```python
from src.llm_adapters import get_llm_adapter

llm = get_llm_adapter()

result = llm.generate(
    prompt="Extract facts from this paper...",
    system_prompt="You are a scientific data extractor."
)

print(result["content"])
print(f"Cost: ${result['cost']:.6f}")
```

**Embeddings:**
```python
texts = ["text 1", "text 2", "text 3"]
embeddings = llm.embed(texts)
```

**Streaming:**
```python
for chunk in llm.stream_generate("Tell me about aging"):
    print(chunk, end="", flush=True)
```

---

## ğŸ› ï¸ Supported Providers

### OpenAI (ChatGPT)
- **Model:** gpt-4o-mini
- **Embeddings:** text-embedding-3-small
- **Cost:** ~$0.15 input, ~$0.60 output per 1M tokens

### Ollama (Local)
- **Model:** llama3.1:8b (configurable)
- **Embeddings:** nomic-embed-text
- **Cost:** $0 (runs locally)

**Install Ollama models:**
```bash
ollama pull llama3.1:8b
ollama pull nomic-embed-text
```

---

## ğŸ“š Paper Fetchers

### Fetching Papers from PubMed

```python
from src.fetchers import get_fetcher

# Get PubMed fetcher
fetcher = get_fetcher("pubmed")

# Search for papers
pmids = fetcher.search("caloric restriction aging", max_results=10)

# Fetch paper metadata
paper = fetcher.fetch_paper(pmids[0])
print(f"Title: {paper.title}")
print(f"Authors: {', '.join(paper.authors)}")
print(f"Abstract: {paper.abstract}")

# Or search and fetch in one call
papers = fetcher.search_and_fetch("rapamycin longevity", max_results=5)
```

**Run example:**
```bash
python scripts/example_fetchers.py
```

---

## ğŸ§ª Testing

### Running Tests

```bash
# Install dependencies (including pytest)
pip install -r requirements.txt

# Run all tests
pytest

# Run with verbose output
pytest -v

# Run only integration tests
pytest tests/integration/ -v

# Run with coverage report
pytest --cov=src --cov-report=term-missing

# Generate HTML coverage report
pytest --cov=src --cov-report=html
# Open htmlcov/index.html in browser
```

### Test Structure

```
tests/
â”œâ”€â”€ conftest.py              # Pytest fixtures
â””â”€â”€ integration/
    â””â”€â”€ test_pubmed_fetcher.py  # PubMed API tests
```

**Integration tests:**
- Test real API calls to PubMed
- Require internet connection
- Can use NCBI_API_KEY for faster rate limits (10 req/sec vs 3)

**Tips:**
- Integration tests are fast (~5-10 seconds)
- No API key needed (but recommended for speed)
- Tests use real PubMed data

---

## ğŸ“ Project Structure

```
AAIAA/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ llm_config.yaml       # LLM provider configuration
â”‚   â”‚   â”œâ”€â”€ fetcher_config.yaml   # Paper fetcher configuration
â”‚   â”‚   â””â”€â”€ settings.py           # Config loader
â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â”œâ”€â”€ base_adapter.py       # Abstract LLM adapter
â”‚   â”‚   â”œâ”€â”€ openai_adapter.py     # OpenAI implementation
â”‚   â”‚   â”œâ”€â”€ ollama_adapter.py     # Ollama implementation
â”‚   â”‚   â””â”€â”€ factory.py            # Adapter factory
â”‚   â””â”€â”€ fetchers/
â”‚       â”œâ”€â”€ base_fetcher.py       # Abstract fetcher
â”‚       â”œâ”€â”€ pubmed_fetcher.py     # PubMed E-utilities
â”‚       â””â”€â”€ factory.py            # Fetcher factory
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py               # Pytest fixtures
â”‚   â””â”€â”€ integration/
â”‚       â””â”€â”€ test_pubmed_fetcher.py # PubMed integration tests
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ example_adapters.py       # LLM adapter examples
â”‚   â””â”€â”€ example_fetchers.py       # Paper fetcher examples
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ Claude.md                 # Project context
â”‚   â””â”€â”€ singularis_project_doc.md # Full documentation
â”œâ”€â”€ .env.example                  # Environment template
â”œâ”€â”€ requirements.txt              # Dependencies
â””â”€â”€ README.md                     # This file
```

---

## ğŸ¤– Telegram Bot

**PDF to Knowledge Graph Bot**

ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… ÑÑ‚Ğ°Ñ‚ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· Telegram! ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ÑŒÑ‚Ğµ PDF - Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚Ğµ Ğ³Ñ€Ğ°Ñ„ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹.

### Quick Start

1. ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚Ğµ Ñ‚Ğ¾ĞºĞµĞ½ Ğ¾Ñ‚ [@BotFather](https://t.me/botfather)
2. Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ğ² `.env`:
   ```bash
   TELEGRAM_BOT_TOKEN=your_bot_token
   ```
3. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ Ğ±Ğ¾Ñ‚Ğ°:
   ```bash
   python scripts/run_telegram_bot.py
   ```

### Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ

- âœ… ĞŸÑ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ PDF Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… ÑÑ‚Ğ°Ñ‚ĞµĞ¹
- âœ… Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ ÑÑƒÑ‰Ğ½Ğ¾ÑÑ‚Ğ¸ (Ñ„Ğ°ĞºÑ‚Ñ‹, Ğ³Ğ¸Ğ¿Ğ¾Ñ‚ĞµĞ·Ñ‹, ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹, Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹)
- âœ… Ğ¡Ñ‚Ñ€Ğ¾Ğ¸Ñ‚ Ğ³Ñ€Ğ°Ñ„ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹
- âœ… Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ SVG Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
- âœ… Rate limiting (5 Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²/Ñ‡Ğ°Ñ)
- âœ… Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

### ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½ĞµĞµ

Ğ¡Ğ¼. [`bot/README.md`](bot/README.md) Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¹ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸.

---

## ğŸ“ Next Steps

1. âœ… LLM adapters created
2. âœ… Paper fetchers created (PubMed)
3. âœ… PDF Parser implemented
4. âœ… LLM Pipeline implemented
5. âœ… SVG visualization created
6. âœ… **Telegram Bot completed**
7. ğŸ”„ Create RAG pipeline
8. ğŸ”„ Create UI with Streamlit

---

## ğŸ“š Documentation

See [`docs/singularis_project_doc.md`](docs/singularis_project_doc.md) for full project documentation.
